{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.make_dataset import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Utiliser tensorflow.keras au lieu de keras directement\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.applications import ResNet50, VGG19, InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from src.trainer import ImageTrainer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from src.utils import plot_confusion_matrix\n",
    "from src.utils import datagen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Settings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(project_dir, 'data', 'Garbage_classification','Garbage_classification')\n",
    "logger.info(f\"\\nProject directory: {project_dir} \\nData directory: {data_path}\")\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Collection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_data(True)\n",
    "# Afficher le nombre d'images et de labels chargés\n",
    "print(f'Nombre d\\'images chargées: {len(images)}')\n",
    "print(f'Nombre de labels chargés: {len(labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>EDA: Exploratory Data Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher l'image avec son label\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(images[2500])\n",
    "plt.title(f\"Label: {labels[2500]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List categories\n",
    "categories = os.listdir(data_path)\n",
    "print(\"Categories:\", categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images in each category\n",
    "category_counts = {category: len(os.listdir(os.path.join(data_path, category))) for category in categories}\n",
    "category_counts_df = pd.DataFrame.from_dict(category_counts, orient='index', columns=['Count'])\n",
    "print(category_counts_df)\n",
    "\n",
    "# Plot the number of images per category\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=category_counts_df.index, y=category_counts_df['Count'])\n",
    "plt.title('Number of images per category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Visualize some images from each category\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    img_path = os.path.join(data_path, category, os.listdir(os.path.join(data_path, category))[0])\n",
    "    img = load_img(img_path, target_size=(128, 128))\n",
    "    img_array = img_to_array(img, dtype=np.uint8)\n",
    "\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(img_array)\n",
    "    plt.title(category)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store image dimensions\n",
    "image_dimensions = []\n",
    "\n",
    "# Iterate over each category and each image within the category\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_path, category)\n",
    "    for img_name in os.listdir(category_path):\n",
    "        img_path = os.path.join(category_path, img_name)\n",
    "        with Image.open(img_path) as img:\n",
    "            image_dimensions.append(img.size)  # img.size returns (width, height)\n",
    "\n",
    "# Convert the list of dimensions to a DataFrame for better analysis\n",
    "image_dimensions_df = pd.DataFrame(image_dimensions, columns=['Width', 'Height'])\n",
    "\n",
    "# Check if all dimensions are the same\n",
    "unique_dimensions = image_dimensions_df.drop_duplicates()\n",
    "if len(unique_dimensions) == 1:\n",
    "    print(f\"All images have the same size: {unique_dimensions.iloc[0].to_dict()}\")\n",
    "else:\n",
    "    print(\"Not all images have the same size.\")\n",
    "    print(\"Different image sizes found:\")\n",
    "    print(unique_dimensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modeling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape=(128, 128, 3), num_classes=6):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = create_cnn_model(input_shape=(128, 128, 3), num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance de ImageTrainer avec les images, labels et le modèle\n",
    "trainer = ImageTrainer(data=images, labels=labels, model=cnn_model)\n",
    "\n",
    "# Entraîner le modèle et évaluer les métriques\n",
    "train_metrics, val_metrics, test_metrics, sk_model = trainer.train()\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(train_metrics[\"confusion_matrix\"], \"Confusion Matrix (Train)\")\n",
    "plot_confusion_matrix(test_metrics[\"confusion_matrix\"], \"Confusion Matrix (Test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tester d'autres modéles</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape=(128, 128, 3), num_classes=6):\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_vgg19_model(input_shape=(128, 128, 3), num_classes=6):\n",
    "    base_model = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_inception_model(input_shape=(128, 128, 3), num_classes=6):\n",
    "    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameters to benchmark\n",
    "ESTIMATOR_PARAMS = {\n",
    "    \"VGG16\": {\"estimator\": create_vgg19_model, \"params\": {\"input_shape\": (128, 128, 3), \"num_classes\": 6}},\n",
    "    \"InceptionV3\": {\"estimator\": create_inception_model, \"params\": {\"input_shape\": (128, 128, 3), \"num_classes\": 6}},\n",
    "    \"CNN\": {\"estimator\": create_cnn_model, \"params\": {\"input_shape\": (128, 128, 3), \"num_classes\": 6}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment if not exists\n",
    "exp_name = \"image-classification\"\n",
    "experiment = mlflow.get_experiment_by_name(exp_name)\n",
    "if not experiment:\n",
    "    experiment_id = mlflow.create_experiment(exp_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "logger.info(f\"Experiment id: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)  # Assuming your images have 3 color channels (RGB)\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "# Loop through the models and their configurations\n",
    "for model_name, model_configs in ESTIMATOR_PARAMS.items():\n",
    "    logger.info(f\"{model_name} \\n{model_configs}\")\n",
    "\n",
    "    estimator = model_configs[\"estimator\"]\n",
    "    params = model_configs[\"params\"]\n",
    "\n",
    "    # Initialiser le modèle Keras directement\n",
    "    model = estimator(**params)\n",
    "    \n",
    "    # Initialize and use the ImageTrainer with the current model and data augmentation\n",
    "    trainer = ImageTrainer(data=images, labels=labels, model=model)\n",
    "    train_metrics, val_metrics, test_metrics, trained_model = trainer.train()\n",
    "    \n",
    "    # Convert confusion matrix to DataFrame\n",
    "    class_names = list(trainer.label_mapping.keys())  # Get class names from label mapping\n",
    "    train_conf_matrix_df = pd.DataFrame(train_metrics[\"confusion_matrix\"], index=class_names, columns=class_names)\n",
    "    val_conf_matrix_df = pd.DataFrame(val_metrics[\"confusion_matrix\"], index=class_names, columns=class_names)\n",
    "    test_conf_matrix_df = pd.DataFrame(test_metrics[\"confusion_matrix\"], index=class_names, columns=class_names)\n",
    "\n",
    "    # Start MLflow run\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "            \"model_name\": model_name,\n",
    "            \"target_size\": trainer.target_size,\n",
    "            \"batch_size\": trainer.batch_size,\n",
    "            \"epochs\": trainer.epochs,\n",
    "            \"test_size\": trainer.test_size,\n",
    "            \"random_state\": trainer.random_state\n",
    "        })\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"train_accuracy\": train_metrics[\"accuracy\"],\n",
    "            \"val_accuracy\": val_metrics[\"accuracy\"],\n",
    "            \"test_accuracy\": test_metrics[\"accuracy\"]\n",
    "        })\n",
    "        # Log classification report as CSV\n",
    "        train_metrics[\"classification_report\"].to_csv(\"train_classification_report.csv\")\n",
    "        val_metrics[\"classification_report\"].to_csv(\"val_classification_report.csv\")\n",
    "        test_metrics[\"classification_report\"].to_csv(\"test_classification_report.csv\")\n",
    "        mlflow.log_artifact(\"train_classification_report.csv\")\n",
    "        mlflow.log_artifact(\"val_classification_report.csv\")\n",
    "        mlflow.log_artifact(\"test_classification_report.csv\")\n",
    "\n",
    "        # Log confusion matrix as CSV\n",
    "        train_conf_matrix_df.to_csv(\"train_confusion_matrix.csv\")\n",
    "        val_conf_matrix_df.to_csv(\"val_confusion_matrix.csv\")\n",
    "        test_conf_matrix_df.to_csv(\"test_confusion_matrix.csv\")\n",
    "        mlflow.log_artifact(\"train_confusion_matrix.csv\")\n",
    "        mlflow.log_artifact(\"val_confusion_matrix.csv\")\n",
    "        mlflow.log_artifact(\"test_confusion_matrix.csv\")\n",
    "\n",
    "        # Log model\n",
    "        #mlflow.keras.log_model(trained_model, artifact_path=f\"model_{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ResNet50\": {\"estimator\": create_resnet_model, \"params\": {\"input_shape\": (128, 128, 3), \"num_classes\": 6}},"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "original_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
